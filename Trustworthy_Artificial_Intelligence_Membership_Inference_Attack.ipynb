{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c4fd6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd64b3c2",
   "metadata": {},
   "source": [
    "# Load and process MNIST data for image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950f1b90",
   "metadata": {},
   "source": [
    "For the membership inference attack introduced in class, the first step is to synthesize a dataset for a shadow model (surrogate model). Here, we sample this dataset directly from the loaded data and focus on the second step that constructs a set of shadow models to obtain member and non-member confidence scores for attack model training.\n",
    "\n",
    "`dataset_for_shadow` is the data used for shadow model training\n",
    "\n",
    "`dataset_for_target` is the data used for target model training\n",
    "\n",
    "`dataset_for_shadow` and `dataset_for_target` should be disjoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d5cebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize images and convert the dataset into Tensor used by PyTorch\n",
    "transform=transforms.Compose([\n",
    "         transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "#Download the MNIST data directly from PyTorch\n",
    "dataset_for_shadow = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "dataset_for_target = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "class_names = ['0', '1', '2', '3', '4',\n",
    "               '5', '6', '7', '8', '9']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1e83e7",
   "metadata": {},
   "source": [
    "# Prepare Datasets for target model and shadow models (surrogate models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93ba0de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preparation for shadow models\n",
    "\n",
    "#The number of shadow models\n",
    "num_shadow_models = 10\n",
    "\n",
    "#The size of samples for each shadow model\n",
    "shadow_size = 2500\n",
    "\n",
    "#List of training datasets: each training set is used to train one shadow model\n",
    "list_train_loader = []\n",
    "#List of Unseen datasets: one for each shadow model\n",
    "list_unseen_loader = []\n",
    "\n",
    "for _ in range(num_shadow_models):\n",
    "    #training data and unseen data should be disjoint\n",
    "    #Obtain the indices for training data and unseen data\n",
    "    train_indices = np.random.choice(len(dataset_for_shadow), shadow_size, replace=False)\n",
    "    unseen_indices = np.setdiff1d(np.arange(len(dataset_for_shadow)), train_indices)\n",
    "    unseen_indices = np.random.choice(unseen_indices, shadow_size, replace=False)\n",
    "    \n",
    "    subset_train = Subset(dataset_for_shadow, train_indices)\n",
    "    subset_unseen = Subset(dataset_for_shadow, unseen_indices)\n",
    "    \n",
    "    subset_train_loader = DataLoader(subset_train, batch_size=32, shuffle=True, num_workers=0)\n",
    "    subset_unseen_loader = DataLoader(subset_unseen, batch_size=32, shuffle=False, num_workers=0)\n",
    "    \n",
    "    list_train_loader.append(subset_train_loader)\n",
    "    list_unseen_loader.append(subset_unseen_loader)\n",
    "\n",
    "\n",
    "#Data preparation for target model\n",
    "target_train_loader = DataLoader(dataset_for_target, batch_size=32, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c3a0a0",
   "metadata": {},
   "source": [
    "# Train a target model\n",
    "\n",
    "We need to a target model, such that the attack can perform membership inference attack to determine if a record is used to train this target model or not\n",
    "\n",
    "#### Set up model definition, hyperparameters, and  the train and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b28da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 5\n",
    "learning_rate = 0.01\n",
    "weight_decay = 5e-4\n",
    "lossfunction = nn.CrossEntropyLoss()\n",
    "\n",
    "class ClassificationNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassificationNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50) \n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x)) \n",
    "        x = F.max_pool2d(x, 2)   \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "target_model = ClassificationNet()\n",
    "target_optimizer = optim.Adam(target_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "#Pre-define the training function\n",
    "def train(class_model, optimizer, loss_function, epoch, train_dataloader):\n",
    "    class_model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    train_total, train_correct = 0.0, 0.0    \n",
    "    \n",
    "    for i, (features, labels) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = class_model(features)\n",
    "\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print statistics\n",
    "        running_loss += loss.item()\n",
    "        _, train_predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (train_predicted == labels).sum().item()\n",
    "\n",
    "    print(\"epoch (%d): Train accuracy: %.4f, loss: %.3f\" % (epoch, train_correct/train_total, running_loss/train_total))\n",
    " \n",
    "\n",
    "#Pre-define the test function\n",
    "def test(class_model, test_dataloader):\n",
    "    class_model.eval()\n",
    "    \n",
    "    test_correct, test_total = 0.0, 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_dataloader:\n",
    "            outputs = class_model(features)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test accuracy: %.4f' % (test_correct / test_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d6c8f4",
   "metadata": {},
   "source": [
    "#### Train the target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1acf8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (1): Train accuracy: 0.8971, loss: 0.010\n",
      "epoch (2): Train accuracy: 0.9640, loss: 0.004\n",
      "epoch (3): Train accuracy: 0.9736, loss: 0.003\n",
      "epoch (4): Train accuracy: 0.9745, loss: 0.002\n",
      "epoch (5): Train accuracy: 0.9780, loss: 0.002\n"
     ]
    }
   ],
   "source": [
    "#Train the target model\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(target_model, target_optimizer, lossfunction, epoch, target_train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb36ec",
   "metadata": {},
   "source": [
    "# Train a set of shadow models\n",
    "\n",
    "####  Use `shadow_loader` to train a shadow model and create member dataset vs non-member dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b1613db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Shadow model: 1-----------\n",
      "epoch (1): Train accuracy: 0.7012, loss: 0.028\n",
      "epoch (2): Train accuracy: 0.9188, loss: 0.008\n",
      "epoch (3): Train accuracy: 0.9540, loss: 0.004\n",
      "epoch (4): Train accuracy: 0.9656, loss: 0.003\n",
      "epoch (5): Train accuracy: 0.9620, loss: 0.004\n",
      "-----------Shadow model: 2-----------\n",
      "epoch (1): Train accuracy: 0.7632, loss: 0.023\n",
      "epoch (2): Train accuracy: 0.9520, loss: 0.005\n",
      "epoch (3): Train accuracy: 0.9536, loss: 0.004\n",
      "epoch (4): Train accuracy: 0.9816, loss: 0.002\n",
      "epoch (5): Train accuracy: 0.9716, loss: 0.003\n",
      "-----------Shadow model: 3-----------\n",
      "epoch (1): Train accuracy: 0.6888, loss: 0.028\n",
      "epoch (2): Train accuracy: 0.9256, loss: 0.007\n",
      "epoch (3): Train accuracy: 0.9508, loss: 0.005\n",
      "epoch (4): Train accuracy: 0.9596, loss: 0.004\n",
      "epoch (5): Train accuracy: 0.9772, loss: 0.002\n",
      "-----------Shadow model: 4-----------\n",
      "epoch (1): Train accuracy: 0.7088, loss: 0.027\n",
      "epoch (2): Train accuracy: 0.9260, loss: 0.008\n",
      "epoch (3): Train accuracy: 0.9484, loss: 0.005\n",
      "epoch (4): Train accuracy: 0.9652, loss: 0.004\n",
      "epoch (5): Train accuracy: 0.9576, loss: 0.004\n",
      "-----------Shadow model: 5-----------\n",
      "epoch (1): Train accuracy: 0.7540, loss: 0.023\n",
      "epoch (2): Train accuracy: 0.9396, loss: 0.006\n",
      "epoch (3): Train accuracy: 0.9516, loss: 0.005\n",
      "epoch (4): Train accuracy: 0.9692, loss: 0.003\n",
      "epoch (5): Train accuracy: 0.9724, loss: 0.002\n",
      "-----------Shadow model: 6-----------\n",
      "epoch (1): Train accuracy: 0.7108, loss: 0.028\n",
      "epoch (2): Train accuracy: 0.9180, loss: 0.009\n",
      "epoch (3): Train accuracy: 0.9464, loss: 0.006\n",
      "epoch (4): Train accuracy: 0.9572, loss: 0.004\n",
      "epoch (5): Train accuracy: 0.9664, loss: 0.003\n",
      "-----------Shadow model: 7-----------\n",
      "epoch (1): Train accuracy: 0.7288, loss: 0.025\n",
      "epoch (2): Train accuracy: 0.9272, loss: 0.007\n",
      "epoch (3): Train accuracy: 0.9504, loss: 0.005\n",
      "epoch (4): Train accuracy: 0.9620, loss: 0.004\n",
      "epoch (5): Train accuracy: 0.9736, loss: 0.003\n",
      "-----------Shadow model: 8-----------\n",
      "epoch (1): Train accuracy: 0.7676, loss: 0.023\n",
      "epoch (2): Train accuracy: 0.9292, loss: 0.007\n",
      "epoch (3): Train accuracy: 0.9424, loss: 0.006\n",
      "epoch (4): Train accuracy: 0.9604, loss: 0.004\n",
      "epoch (5): Train accuracy: 0.9704, loss: 0.002\n",
      "-----------Shadow model: 9-----------\n",
      "epoch (1): Train accuracy: 0.7128, loss: 0.027\n",
      "epoch (2): Train accuracy: 0.9272, loss: 0.008\n",
      "epoch (3): Train accuracy: 0.9516, loss: 0.005\n",
      "epoch (4): Train accuracy: 0.9620, loss: 0.004\n",
      "epoch (5): Train accuracy: 0.9680, loss: 0.003\n",
      "-----------Shadow model: 10-----------\n",
      "epoch (1): Train accuracy: 0.6976, loss: 0.029\n",
      "epoch (2): Train accuracy: 0.9376, loss: 0.007\n",
      "epoch (3): Train accuracy: 0.9532, loss: 0.005\n",
      "epoch (4): Train accuracy: 0.9640, loss: 0.004\n",
      "epoch (5): Train accuracy: 0.9748, loss: 0.002\n",
      "torch.Size([25000, 10])\n",
      "torch.Size([25000, 10])\n"
     ]
    }
   ],
   "source": [
    "#Pre-define a function to obtain member_set and non_member_set for a given shadow model\n",
    "def make_member_nonmember(shadow_model, shadow_loader, unseen_loader):   \n",
    "    shadow_model.eval()\n",
    "    \n",
    "    member_set, non_member_set = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, labels in shadow_loader:\n",
    "            outputs = shadow_model(features)\n",
    "            probs = F.softmax(outputs, dim=1).type(torch.FloatTensor)\n",
    "            member_set.append(probs.detach())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, labels in unseen_loader:\n",
    "            outputs = shadow_model(features)\n",
    "            probs = F.softmax(outputs, dim=1).type(torch.FloatTensor)\n",
    "            non_member_set.append(probs.detach())\n",
    "    \n",
    "    member_set = torch.cat(member_set)\n",
    "    non_member_set = torch.cat(non_member_set)\n",
    "    \n",
    "    return member_set, non_member_set\n",
    "\n",
    "    \n",
    "total_members = []\n",
    "total_non_members = []\n",
    "\n",
    "#Train a set of shadow models one by one\n",
    "for shadow_number, shadow_loader in enumerate(list_train_loader):\n",
    "    print(\"-----------Shadow model: {}-----------\".format(shadow_number + 1))\n",
    "    unseen_loader = list_unseen_loader[shadow_number]\n",
    "    \n",
    "    #Shadow model setting\n",
    "    shadow_model = ClassificationNet()\n",
    "    shadow_optimizer = optim.Adam(shadow_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    #Train the target model\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(shadow_model, shadow_optimizer, lossfunction, epoch, shadow_loader)\n",
    "    \n",
    "    #Create member dataset vs non-member dataset based on shadow_model\n",
    "    member_set, non_member_set = make_member_nonmember(shadow_model, shadow_loader, unseen_loader)\n",
    "    \n",
    "    total_members.append(member_set)\n",
    "    total_non_members.append(non_member_set)\n",
    "\n",
    "total_members = torch.cat(total_members)\n",
    "total_non_members = torch.cat(total_non_members)\n",
    "\n",
    "print(total_members.shape)\n",
    "print(total_non_members.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5503666",
   "metadata": {},
   "source": [
    "####  Construct the final dataset for membership inference attack training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80c7f3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "#Concatenate total_members and total_non_members\n",
    "total_members_size = total_members.shape[0]\n",
    "total_non_members_size = total_non_members.shape[0]\n",
    "\n",
    "#Generate labels: member - 1 and non-member - 0\n",
    "total_members_labels = torch.Tensor([1]).repeat(total_members_size)\n",
    "total_non_members_labels = torch.Tensor([0]).repeat(total_non_members_size)\n",
    "\n",
    "#Final data for attack training\n",
    "X = torch.cat((total_members, total_non_members)).numpy()\n",
    "y = torch.cat((total_members_labels, total_non_members_labels)).numpy()\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54628b6",
   "metadata": {},
   "source": [
    "# Train a binary classification model for membership inference attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd4cc11f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5091, F1_score: 0.5038\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "#Data splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "#Attack model training using Logistic Regression\n",
    "log_reg = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Accuracy: %.4f, F1_score: %.4f\" % (accuracy, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e03082",
   "metadata": {},
   "source": [
    "# Use the trained attack model to perform membership inference attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7a53c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5360, F1_score: 0.5312\n"
     ]
    }
   ],
   "source": [
    "test_size = 1000\n",
    "\n",
    "member_indices = np.random.choice(len(dataset_for_target), test_size, replace=False)\n",
    "non_member_indices = np.random.choice(len(dataset_for_shadow), test_size, replace=False)\n",
    "\n",
    "member_test = Subset(dataset_for_target, member_indices)\n",
    "non_member_test = Subset(dataset_for_shadow, non_member_indices)\n",
    "\n",
    "member_test_loader = DataLoader(member_test, batch_size=32, shuffle=False, num_workers=0)\n",
    "non_member_test_loader = DataLoader(non_member_test, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "#Pass the data to the target model and obtain confidence scores\n",
    "member_test, non_member_test = make_member_nonmember(target_model, member_test_loader, non_member_test_loader)\n",
    "\n",
    "#Generate labels: member - 1 and non-member - 0\n",
    "member_test_labels = torch.Tensor([1]).repeat(test_size)\n",
    "non_member_test_labels = torch.Tensor([0]).repeat(test_size)\n",
    "\n",
    "#Final data for attack testing\n",
    "X_membership = torch.cat((member_test, non_member_test)).numpy()\n",
    "y_membership = torch.cat((member_test_labels, non_member_test_labels)).numpy()\n",
    "\n",
    "#Test the membership inference attack model \n",
    "y_pred_membership = log_reg.predict(X_membership)\n",
    "\n",
    "accuracy = accuracy_score(y_membership, y_pred_membership)\n",
    "f1 = f1_score(y_membership, y_pred_membership, average='macro')\n",
    "\n",
    "print(\"Accuracy: %.4f, F1_score: %.4f\" % (accuracy, f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
