{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# A Simple Adversarial Attack Against Machine Learning Using Feature Perturbation\n",
        "\n",
        "In this lab, we will demonstrate how we can algorithmically alter features of an input to attack a pre-trained machine learning model. This lab assumes three inputs:\n",
        "\n",
        "+ A pre-trained classification model, namely ```model```\n",
        "+ An input, namely ```original_input```, whose label is ```original_label``` by the model (i.e., ```original_label = model(original_input)```)\n",
        "+ An target label, namely ```target_label```, which is different from ```original_label```.    \n",
        "\n",
        "The objective of this attack is to automatically generate a new input namely ```adversarial_input``` by minimally purturbing features of ```original_input``` so that ```target_label = model(adversarial_input)```. \n",
        "\n",
        "It is worth noting that this method algorithmically generates ```adversarial_input``` from  ```original_input``` without rigorously proving or verifying the purturbation is *minimized*. Nevertheless, this method can be easily extended to assure the distance between the ```adversarial_input``` and the ```origina_input``` is smaller than a pre-defined value.  \n",
        "\n"
      ],
      "metadata": {
        "id": "nFSMEyCaQqgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1. Build A Classification Model\n",
        "\n",
        "### Exploring The Data\n",
        "\n",
        "We use the iris data to build a classification model. The iris data has 4 features and 3 classes. Therefore, the model needs to perform multi-class classification. \n",
        "\n"
      ],
      "metadata": {
        "id": "BdfY5rA1MJVP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRTsuREGhaDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5cd9fdc-193d-497d-db3b-3e5e3ff3b2f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of features:  3\n",
            "The number of classes:  3\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.compat.long))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.compat.long))\n",
        "\n",
        "_, n_input_features = X_train.shape\n",
        "\n",
        "n_output_features = torch.unique(y_train).shape[0]\n",
        "print(\"The number of features: \", n_output_features)\n",
        "print(\"The number of classes: \", n_output_features)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define A Model\n",
        "\n",
        "Since the iris data are relatively simple, we use a linear model with one layer. We use Pytorch to implement this model. "
      ],
      "metadata": {
        "id": "EhCsTfWkNzxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A model implemented using PyTorch\n",
        "class IRISModel(nn.Module):\n",
        "  def __init__(self, n_input_features, n_output_features):\n",
        "    super(IRISModel, self).__init__()\n",
        "    self.linear = nn.Linear(n_input_features, n_output_features, bias = False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = self.linear(x)\n",
        "    return y"
      ],
      "metadata": {
        "id": "0thHhTtrreYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train The Model\n",
        "\n",
        "Since this is a multi-class classification problem, we have used ```CrossEntropyLoss()```. After 5000 rounds of training, the model has accomplished a high detection accuracy of 98%. "
      ],
      "metadata": {
        "id": "7w8Q9pgwN8hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = IRISModel(n_input_features, n_output_features)\n",
        "lr = 0.01\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
        "torch.manual_seed(247)\n",
        "\n",
        "n_iter = 5000\n",
        "\n",
        "for i in range(n_iter):\n",
        "\n",
        "  y_predict = model(X_train)\n",
        "  loss = criterion(y_predict, y_train)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if i % 500 == 0:\n",
        "    with torch.no_grad():\n",
        "      y_predict = model(X_train)\n",
        "      loss = criterion(y_predict, y_train)\n",
        "      _, y_predict = torch.max(y_predict, dim = 1)\n",
        "      cnt_matched = (y_predict == y_train).sum().item()\n",
        "      cnt_all = y_predict.shape[0]\n",
        "      accuracy_train = cnt_matched / cnt_all\n",
        "      print(\"[%d]: loss: %f, accuracy:%f\" % (i, loss, accuracy_train))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPuwHQWp2gjf",
        "outputId": "44978e7e-b7b9-4417-d974-c0fe80009f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]: loss: 1.430276, accuracy:0.303571\n",
            "[500]: loss: 0.423566, accuracy:0.875000\n",
            "[1000]: loss: 0.341122, accuracy:0.946429\n",
            "[1500]: loss: 0.292505, accuracy:0.982143\n",
            "[2000]: loss: 0.258522, accuracy:0.982143\n",
            "[2500]: loss: 0.233166, accuracy:0.982143\n",
            "[3000]: loss: 0.213481, accuracy:0.982143\n",
            "[3500]: loss: 0.197744, accuracy:0.982143\n",
            "[4000]: loss: 0.184870, accuracy:0.982143\n",
            "[4500]: loss: 0.174138, accuracy:0.982143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring The Trained Model\n",
        "\n",
        "We print the weights of trained model. Since the model has only one layer, these weights manifest the feature importance. Specifically, each row, which corresponds to each target class, shows how each feature contributes to the final score of this class. For example, the last row shows that feature 3 (with weight of 2.6633) contributes most to the 3rd class. "
      ],
      "metadata": {
        "id": "sy1RLzfLOjrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.linear.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHFGUPIjYKRS",
        "outputId": "a85b5b2c-3515-4534-9693-2fc11bed1b2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.9818,  1.2395, -2.2441, -0.6774],\n",
            "        [ 0.7079, -0.4689,  0.2842, -1.0578],\n",
            "        [-1.3512, -1.4727,  2.6633,  1.6054]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2. Identify An Original Input\n",
        "\n",
        "You can create an arbitrary input as the original input. Here we use [6.0, 2.2, 4, 1]. \n",
        "\n",
        "We then apply the trained model to classify this input and we get the label of 1, which corresponds to the class of versicolor. "
      ],
      "metadata": {
        "id": "NO7ZYGRCPPyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_input = np.array([6.0, 2.2, 4, 1])\n",
        "original_input_tensor = torch.from_numpy(original_input.astype(np.float32))\n",
        "\n",
        "with torch.no_grad():\n",
        "  #prob_predict, label_predict = torch.max(model(original_input), dim=1)\n",
        "  r = model(original_input_tensor)\n",
        "  m = nn.Softmax(dim = 1)\n",
        "  r = m(r.reshape(-1, 3))\n",
        "  prob_predict, label_predict = torch.max(r, dim=1)\n",
        "\n",
        "original_label = label_predict\n",
        "print(original_label)\n",
        "print(iris.target_names[original_label])\n"
      ],
      "metadata": {
        "id": "Kp7ITJOZ0J7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d5d8b97-6960-4047-e935-23d0d1f13016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1])\n",
            "versicolor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3. Generating An Adversarial Example\n",
        "\n",
        "## Identify All Candidate Guidence Instances and Sort Them\n",
        "\n",
        "In order to generate an adversarial example, we first define a label that is different from the label of the original input.  \n",
        "\n",
        "As you can find in the previous section, the label of the original input is ```versiclor``` (i.e., class 1). Therefore, here we assign ```target_label``` as 2. \n",
        "\n",
        "We will next identify all inputs that are classified as class 2 and store them into ```all_guidence_candidates```. We next evaluate the distance between the ```original_input``` and all inputs in ```all_guidence_candidates```. We sort indices of  ```all_guidence_candidates``` according to distance values and then store them into ```ordered_neighbors_indices```. Inputs in ```all_guidence_candidates``` with smaller distances are preferred since they imply smaller perturbation when we alter the ```original_input```. "
      ],
      "metadata": {
        "id": "OxO-K798P7pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import manhattan_distances\n",
        "\n",
        "target_label = 2\n",
        "\n",
        "with torch.no_grad():\n",
        "  predict = model(X_train)\n",
        "  _, labels_predict = torch.max(predict, dim=1)\n",
        "  #print(labels_predict)\n",
        "  all_guidence_candidates = X_train[labels_predict == target_label]\n",
        "\n",
        "distances = manhattan_distances(original_input.reshape(-1, 4), all_guidence_candidates)\n",
        "\n",
        "ordered_neighbors_indices = np.argsort(distances[0])\n",
        "\n",
        "#ordered_all_guidence_candidates = all_guidence_candidates[ordered_neighbors_indices]\n"
      ],
      "metadata": {
        "id": "6JfMbkBhewy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify Top-K Stealthy Candidate guidence Instances\n",
        "\n",
        "For each input in ```all_guidence_candidates```, we identify those that have a higher likelihood to be classified as class 1. Note, all inputs in ```all_guidence_candidates``` have been classified as class 2 by our model. Nevertheless, the higher likelihood an input from ```all_guidence_candidates``` has, the closer it is to the decision boundary. Therefore, it is more likely to be a *stealthy* guidence input. \n",
        "\n",
        "\n",
        "We therefore apply our trained model and sort indices of ```all_guidence_candidates``` based on the probability of being classified as ```original_input```. We only preserve the top K (i.e., 10) inputs that are closest to the decision boundary and store them in ```top_k_candidates_using_prob```. \n",
        "\n"
      ],
      "metadata": {
        "id": "OD8_lENefVN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import paired_euclidean_distances\n",
        "\n",
        "k = 10\n",
        "\n",
        "with torch.no_grad():\n",
        "  predict = model(all_guidence_candidates)\n",
        "  m = nn.Softmax(dim=1)\n",
        "  prob = m(predict)[:, original_label]\n",
        "  prob = prob.squeeze().numpy()\n",
        "\n",
        "\n",
        "ordered_index_using_prob = np.argsort(prob)\n",
        "ordered_index_using_prob = ordered_index_using_prob[::-1]\n",
        "top_k_candidates_using_prob = ordered_index_using_prob[:k]\n",
        "print(top_k_candidates_using_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0Qv-ZTy6Oy3",
        "outputId": "20099c5b-cdf7-4702-eb6d-895d5b87997c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[37 26  8 30  7 31 40 21  1 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identify The Best Guidence Instances\n",
        "\n",
        "We next enumerate each index in ```ordered_neighbors_indices``` and evaluate whehter it is in the ```top_k_candidates_using_prob```. If so, this input will be identified as the ```best_target_instance_index```. \n",
        "\n",
        "It is worth noting that it is possible that no index in ```ordered_neighbors_indices``` belongs to ```top_k_candidates_using_prob```. In this case, the ```best_target_instance_index``` is the first input in ```ordered_neighbors_indices```, i.e., the input in ```ordered_neighbors_indices``` that has the smallest distance with the original_input (see the initialization of ```best_target_instance_index```). "
      ],
      "metadata": {
        "id": "hZU5VhVchmgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_target_instance_index = ordered_neighbors_indices[0]\n",
        "\n",
        "for i in ordered_neighbors_indices:\n",
        "  if i in top_k_candidates_using_prob:\n",
        "    best_target_instance_index = i\n",
        "    break\n",
        "\n",
        "best_target = all_guidence_candidates[best_target_instance_index]\n",
        "print(original_input)\n",
        "print(best_target)                                            "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnRMLdNJ64BW",
        "outputId": "2b1e79d7-028e-48db-d138-92a37d3a7058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6.  2.2 4.  1. ]\n",
            "tensor([6.3000, 2.5000, 4.9000, 1.5000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjust The Original Input Oriented by The Best Guidence Instance\n",
        "\n",
        "We now have the best guidence input. We now adjust ```original_input``` so that it moves towards ```best_target```. \n",
        "\n",
        "Our adjustment leverages the feature importance. Specifically, it starts with the feature that contributes most to the target class. We continuously evaluate whether the adjusted ```original_input``` is classified as the target_label. If so, we generate the ```adversarial_example```. \n",
        "\n",
        "For our example, our algoirthm only changes the third feature from 4 to 4.9 and the trained model classifies the ```adversarial_example``` as 2. \n"
      ],
      "metadata": {
        "id": "vh9xcCk3jghg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.linear.weight[target_label])\n",
        "ordered_feature_idx_using_importance = np.argsort(model.linear.weight[2].detach().numpy())[::-1]\n",
        "print(\"Feature Indices Ordered by Importance: \", ordered_feature_idx_using_importance)\n",
        "print(\"Features Ordered by Importance: \", [iris.feature_names[i] for i in ordered_feature_idx_using_importance])\n",
        "\n",
        "adversarial_example = torch.from_numpy(original_input.copy().astype(np.float32))\n",
        "\n",
        "\n",
        "for feature in ordered_feature_idx_using_importance:\n",
        "  adversarial_example[feature] = best_target[feature]\n",
        "  with torch.no_grad():\n",
        "    predict = model(adversarial_example)\n",
        "    label_predict = torch.argmax(predict)\n",
        "    if(label_predict == target_label):\n",
        "      break\n",
        "\n",
        "#with torch.no_grad():\n",
        "#  predict = model(torch.from_numpy(original_input.astype(np.float32)))\n",
        "#  label_predict = torch.argmax(predict)\n",
        "#  print(label_predict)\n",
        "#  predict = model(adversarial_example)\n",
        "#  label_predict = torch.argmax(predict)\n",
        "#  print(label_predict)\n",
        "\n",
        "print(\"original_input:\", original_input)\n",
        "print(\"best target input:\", best_target.numpy())\n",
        "print(\"The adversarial example:\", adversarial_example.numpy())\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_Y5H_1TEY5Hq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee1e010d-893a-4639-84c0-4b0f4c946d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.3512, -1.4727,  2.6633,  1.6054], grad_fn=<SelectBackward0>)\n",
            "Feature Indices Ordered by Importance:  [2 3 0 1]\n",
            "Features Ordered by Importance:  ['petal length (cm)', 'petal width (cm)', 'sepal length (cm)', 'sepal width (cm)']\n",
            "original_input: [6.  2.2 4.  1. ]\n",
            "best target input: [6.3 2.5 4.9 1.5]\n",
            "The adversarial example: [6.  2.2 4.9 1.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UEH9UPMj63YA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}